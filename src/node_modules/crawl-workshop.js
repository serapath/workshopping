
module.exports = crawlworkshop

async function crawlworkshop (data, href) {
  if (href) {
    const needs = data.needs.map((x, i) => {
      x = x.split('?')[0]
      if (!x.includes('://')) x = 'https://' + x
      if (!x.endsWith('.html') && !x.endsWith('/')) x = x + '/'
      return {
        url: new URL('./workshop.json', x).href,
        parentIds: [],
        id: `needs_${i + 1}`, // @TODO: make something unique, like `href + i`?
        title: `foobar_${i + 1}` // @TODO: fetch from workshop.json
      }
    })
    const unlocks = data.unlocks.map((x, i) => {
      x = x.split('?')[0]
      if (!x.includes('://')) x = 'https://' + x
      if (!x.endsWith('.html') && !x.endsWith('/')) x = x + '/'
      return {
        url: new URL('./workshop.json', x).href,
        parentIds: ['0'],
        id: `unlocks_${i + 1}`, // @TODO: make something unique, like `href + i`?
        title: `barbaz_${i + 1}` // @TODO: fetch from workshop.json
      }
    })
    return [{
      url: href,
      parentIds: [...needs].map(x => x.id),
      title: data.title,
      id: '0'
    }, ...needs, ...unlocks]
  } else {
    throw new Error('@TODO: implement "infinite crawling"')
  }
}
